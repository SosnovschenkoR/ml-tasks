{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сколько страниц книги необходимо прочитать, чтобы узнать 90% всех слов?  \n",
    "* https://ashirobokov.wordpress.com/category/nlp/\n",
    "\n",
    "\n",
    "* Text Classification https://monkeylearn.com/text-classification/\n",
    "* Классификация текстов с помощью мешка слов http://datareview.info/article/klassifikatsiya-tekstov-s-pomoshhyu-meshka-slov-rukovodstvo/\n",
    "* Automated Text Classification Using Machine Learning https://towardsdatascience.com/automated-text-classification-using-machine-learning-3df4f4f9570b\n",
    "* https://ru.coursera.org/lecture/vvedeniye-informatsionnyy-poisk/modiel-mieshka-slov-SgAYN\n",
    "* https://www.kaggle.com/vamsi1251/bag-of-words-model/output\n",
    "* https://github.com/zygmuntz/classifying-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "\n",
    "import pymorphy2\n",
    "from stop_words import get_stop_words\n",
    "\n",
    "page_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "sw = get_stop_words('ru')\n",
    "pyplot.rcParams[\"figure.figsize\"] = (10,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_reader(filename, encoding='utf8', pages=0):\n",
    "    output = \"\"\n",
    "    for row in open(filename, 'r', encoding=encoding):\n",
    "        output += row\n",
    "        if len(output) // page_size + 1 >= pages:\n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    \"\"\"Функция удаляет из текста стоп-слова, \n",
    "    лемматизирует текст и берёт для каждого начальную форму.\n",
    "    \n",
    "    # Arguments\n",
    "        text: исходный текст.\n",
    "    \n",
    "    # Returns\n",
    "        fixed_text: список лемматизированых не-стоп-слов.\n",
    "    \"\"\"\n",
    "    letters_only = re.sub('[^a-zA-Zа-яА-Я]', ' ', text)\n",
    "    fixed_text = []\n",
    "    letters_only = list(filter(None, letters_only.split(' ')))\n",
    "    stop_words = []\n",
    "    for word in letters_only:\n",
    "        # Берём первое совпадения только для простоты.\n",
    "        nf = morph.parse(word)[0].normal_form\n",
    "        if nf in sw:\n",
    "            stop_words.append(nf)\n",
    "            continue\n",
    "        \n",
    "        fixed_text.append(nf)\n",
    "    print(f'Всего стоп-слов: {len(stop_words)}, это {len(stop_words) // page_size + 1} страниц текста')\n",
    "    return fixed_text\n",
    "\n",
    "\n",
    "    \n",
    "def txt_to_pages(filename, encoding='utf8', pages=0):\n",
    "    \"\"\"Функция преобразует текст из текстового файла в \"страницы\"\n",
    "    \n",
    "    # Arguments\n",
    "        filename: путь до текстового файла.\n",
    "        encoding: кодировка исходного файла.\n",
    "    \n",
    "    # Returns\n",
    "        book_pages: список списков лемматизированных слов (\"страниц\")    \n",
    "    \"\"\"\n",
    "    print(\"Чтение файла...\")\n",
    "    #book_text = open(filename, mode='r', encoding=encoding).read()\n",
    "    book_text = file_reader('Tolstoyi_L._Voyinaimir1._Voyina_I_Mir_Kniga_1.txt', encoding='1251', pages=pages)\n",
    "    print(\"Лемматизация...\")\n",
    "    print(f'Используется слов {len(book_text)}, страниц {len(book_text) // page_size + 1}')\n",
    "    book_text = lemmatize(book_text)\n",
    "    \n",
    "    book_pages = []\n",
    "    for i in range(len(book_text) // page_size + 1):\n",
    "        book_pages.append(book_text[i * page_size : i * page_size + page_size])\n",
    "        if pages == len(book_pages) and pages > 0:\n",
    "            break\n",
    "    return book_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_hardness(coverage, percent = 0.9):\n",
    "    \"\"\" Функция вычисляет \"сложность\" книги - \n",
    "            насколько большую часть книги необходимо прочтитать, \n",
    "            чтобы узнать percent всех используемых слов.\n",
    "    \n",
    "    # Arguments\n",
    "        coverage: массив с информацией какой процент книги\n",
    "            можем прочитать, зная слова полученные к i-ой странице.\n",
    "        percent: сколько слов хотим знать.\n",
    "    \n",
    "    # Returns\n",
    "        i: номер страницы.\n",
    "        hardness: какой процент книги будет прочитан к этой странице.\n",
    "    \"\"\"\n",
    "    for i in range(len(coverage)):\n",
    "        if coverage[i] > percent:\n",
    "            break\n",
    "    \n",
    "    hardness = (100 * i) / float(len(coverage))\n",
    "    return i, hardness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage(values, title):\n",
    "    \"\"\" Функция вычисляет всё.\n",
    "    \n",
    "    # Arguments\n",
    "        values: список \"страниц\" книги.\n",
    "    \"\"\"\n",
    "    all_words = list(chain.from_iterable(values))\n",
    "    result = {}\n",
    "    current_text = []\n",
    "    page_counter = 0\n",
    "    file_name = title.lower().replace(' ', '_').replace('\\'','') + '.png'\n",
    "    \n",
    "    counter = Counter()\n",
    "    # \"Счётчик\" всех слов книги. \n",
    "    # Используется для подсчёта процента книги, \n",
    "    # который можно прочитать зная некоторый объём слов. \n",
    "    occurances = Counter(all_words)\n",
    "    \n",
    "    # i-ый элемент: какой процент книги можем прочитать зная слова полученные к i-ой странице.\n",
    "    coverage = []\n",
    "    \n",
    "    # i-ый элемент: какой процент слов используемых в книге знаем к i-ой странице.\n",
    "    uniqueness = []\n",
    "    \n",
    "    # i-ый элемент: сколько уникальных слов используемых в книге знаем к i-ой странице.\n",
    "    total_unique_words_count = []\n",
    "    \n",
    "    total = float(len(all_words))\n",
    "    total_unique = float(len(occurances.keys()))\n",
    "    \n",
    "    print('page\\ttotal\\tpercent of all\\tpercent of book\\tuniqueness')\n",
    "    for page_text in values:\n",
    "        # Обновим счётчик уникальных слов словами с новой страницы.\n",
    "        counter.update(page_text)\n",
    "        \n",
    "        # Посчитаем, сколько вообще раз встречаются слова \n",
    "        # которые уже были встречены к текущей странице.\n",
    "        occured_words_count = sum((occurances[w] for w in counter.keys()))\n",
    "\n",
    "        # Какой процент от всей книги составляют слова, \n",
    "        # которые уже встретили к текущей странице.\n",
    "        _coverage = occured_words_count / total\n",
    "        coverage.append(_coverage)\n",
    "        \n",
    "        # Какой процент от всех уникальных слов встретили к текущей странице.\n",
    "        _uniqueness = len(counter.keys()) / total_unique\n",
    "        uniqueness.append(_uniqueness)\n",
    "        \n",
    "        # Какой процент от книги прошли к текущей странице.\n",
    "        percent_book = page_counter / len(values)\n",
    "        \n",
    "        # Сколько уникальных слов будет известно к текущей странице.\n",
    "        total_unique_words_count.append(len(counter.keys()))\n",
    "        \n",
    "        print('{0}\\t{1}\\t{2:2f}\\t{3:2f}\\t{4:2f}'.format(page_counter, \n",
    "        len(counter.keys()), \n",
    "        _coverage, \n",
    "        percent_book, \n",
    "        _uniqueness))\n",
    "        \n",
    "        result[page_counter] = { \n",
    "            'page': page_counter,\n",
    "            'unique_words': _uniqueness, \n",
    "            'all_words': _coverage\n",
    "        }\n",
    "        page_counter += 1\n",
    "    \n",
    "    percent_df = pd.DataFrame.from_dict(result,orient='index')\n",
    "    \n",
    "    page, hardness = calculate_hardness(coverage)\n",
    "    \n",
    "    print('Всего страниц: {0}'.format(len(values)))\n",
    "    print('Всего слов: {}'.format(len(all_words)))\n",
    "    print('Всего уникальных слов: {}'.format(len(occurances.keys())))\n",
    "    print('Прочитав {0} страниц книги ({1:.2f}% всей книги) вы узнаете {2} уникальных слов.\\nК этой странице будут встречены 90% всех слов книги и {3:.2f}% уникальных.'.format(\n",
    "          page,\n",
    "          hardness,\n",
    "          total_unique_words_count[page],\n",
    "          uniqueness[page] * 100))\n",
    "    \n",
    "    pyplot.plot(percent_df['unique_words'], color='g', label='Уникальные слова')\n",
    "    pyplot.plot(percent_df['all_words'], color='b', label='Все слова')\n",
    "    pyplot.legend(loc=4)\n",
    "    pyplot.title(title)\n",
    "    pyplot.xlabel('Страница')\n",
    "    pyplot.ylabel('Покрытие (%)')\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Чтение файла...\n",
      "Лемматизация...\n",
      "Используется слов 10101, страниц 51\n",
      "Всего стоп-слов: 637, это 4 страниц текста\n"
     ]
    }
   ],
   "source": [
    "war_and_peace_pages = txt_to_pages('Tolstoyi_L._Voyinaimir1._Voyina_I_Mir_Kniga_1.txt', encoding='1251', pages=50)\n",
    "#percentage(war_and_peace_pages, 'Война и мир')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "если a/b  (с остатком)  то = 3.3333333333333335\n",
      "если a//b (без остатка) то = 3\n",
      "если a%b  (остаток)     то = 1\n"
     ]
    }
   ],
   "source": [
    "a = 10\n",
    "b = 3\n",
    "print(f'если a/b  (с остатком)  то = {a/b}')\n",
    "print(f'если a//b (без остатка) то = {a//b}')\n",
    "print(f'если a%b  (остаток)     то = {a%b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
